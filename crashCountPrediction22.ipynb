{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xbart import XBART\n",
    "\n",
    "import random\n",
    "random.seed(6)\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>LEN_SEC</th>\n",
       "      <th>NUM_LANES</th>\n",
       "      <th>MED_WID</th>\n",
       "      <th>shoulder_w</th>\n",
       "      <th>on_system</th>\n",
       "      <th>curve_ind</th>\n",
       "      <th>SUM_length</th>\n",
       "      <th>MAX_EST_CU</th>\n",
       "      <th>ADT_ADJ</th>\n",
       "      <th>...</th>\n",
       "      <th>pop_den</th>\n",
       "      <th>job_den</th>\n",
       "      <th>PrecipInch</th>\n",
       "      <th>HOS_DIST</th>\n",
       "      <th>transit_ind</th>\n",
       "      <th>Cnt_TARGET</th>\n",
       "      <th>transit_density</th>\n",
       "      <th>school_dist</th>\n",
       "      <th>count_nearest_ped</th>\n",
       "      <th>count_nearest_pedfatal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4917</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.187955</td>\n",
       "      <td>36.3</td>\n",
       "      <td>3423</td>\n",
       "      <td>...</td>\n",
       "      <td>40.312369</td>\n",
       "      <td>12.404877</td>\n",
       "      <td>31</td>\n",
       "      <td>3.658316e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.727588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4563</td>\n",
       "      <td>0.075</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529078</td>\n",
       "      <td>36.3</td>\n",
       "      <td>3423</td>\n",
       "      <td>...</td>\n",
       "      <td>40.312369</td>\n",
       "      <td>12.404877</td>\n",
       "      <td>31</td>\n",
       "      <td>3.662212e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.751043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5772</td>\n",
       "      <td>0.265</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190.520702</td>\n",
       "      <td>53.8</td>\n",
       "      <td>3423</td>\n",
       "      <td>...</td>\n",
       "      <td>40.312369</td>\n",
       "      <td>12.404877</td>\n",
       "      <td>31</td>\n",
       "      <td>3.682394e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.820311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8139</td>\n",
       "      <td>0.067</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.198763</td>\n",
       "      <td>55.4</td>\n",
       "      <td>3423</td>\n",
       "      <td>...</td>\n",
       "      <td>40.312369</td>\n",
       "      <td>12.404877</td>\n",
       "      <td>31</td>\n",
       "      <td>3.771042e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.882193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3822</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46.583045</td>\n",
       "      <td>23.3</td>\n",
       "      <td>12998</td>\n",
       "      <td>...</td>\n",
       "      <td>3854.279022</td>\n",
       "      <td>200.470515</td>\n",
       "      <td>51</td>\n",
       "      <td>7.436792e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  LEN_SEC  NUM_LANES  MED_WID  shoulder_w  on_system  curve_ind  \\\n",
       "0      4917    0.030          2        0         0.0          1          1   \n",
       "1      4563    0.075          2        0        10.0          1          1   \n",
       "2      5772    0.265          2        0         6.0          1          1   \n",
       "3      8139    0.067          2        0         0.0          1          1   \n",
       "4      3822    0.225          2        0         4.0          1          1   \n",
       "\n",
       "   SUM_length  MAX_EST_CU  ADT_ADJ  ...      pop_den     job_den  PrecipInch  \\\n",
       "0   25.187955        36.3     3423  ...    40.312369   12.404877          31   \n",
       "1    5.529078        36.3     3423  ...    40.312369   12.404877          31   \n",
       "2  190.520702        53.8     3423  ...    40.312369   12.404877          31   \n",
       "3   56.198763        55.4     3423  ...    40.312369   12.404877          31   \n",
       "4   46.583045        23.3    12998  ...  3854.279022  200.470515          51   \n",
       "\n",
       "       HOS_DIST  transit_ind  Cnt_TARGET  transit_density  school_dist  \\\n",
       "0  3.658316e-06            0           0              0.0     5.727588   \n",
       "1  3.662212e-06            0           0              0.0     5.751043   \n",
       "2  3.682394e-06            0           0              0.0     5.820311   \n",
       "3  3.771042e-06            0           0              0.0     5.882193   \n",
       "4  7.436792e-07            0           0              0.0     0.606257   \n",
       "\n",
       "   count_nearest_ped  count_nearest_pedfatal  \n",
       "0                  0                       0  \n",
       "1                  0                       0  \n",
       "2                  0                       0  \n",
       "3                  0                       0  \n",
       "4                  0                       0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CRIS_processed.csv\")\n",
    "data['DVMT'] = np.log(data['DVMT']+1)\n",
    "# remove the outlier ojectID: 48553\n",
    "data = data[data['count_nearest_ped']<100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OBJECTID                  0\n",
       "LEN_SEC                   0\n",
       "NUM_LANES                 0\n",
       "MED_WID                   0\n",
       "shoulder_w                0\n",
       "on_system                 0\n",
       "curve_ind                 0\n",
       "SUM_length                0\n",
       "MAX_EST_CU                0\n",
       "ADT_ADJ                   0\n",
       "TRK_AADT_P                0\n",
       "AADT2                     0\n",
       "DVMT                      0\n",
       "SPD_MAX                   0\n",
       "RU_1                      0\n",
       "RU_2                      0\n",
       "RU_3                      0\n",
       "RU_4                      0\n",
       "pop_den                   0\n",
       "job_den                   0\n",
       "PrecipInch                0\n",
       "HOS_DIST                  0\n",
       "transit_ind               0\n",
       "Cnt_TARGET                0\n",
       "transit_density           0\n",
       "school_dist               0\n",
       "count_nearest_ped         0\n",
       "count_nearest_pedfatal    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NA\n",
    "np.sum(data.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick view on the distribution of total crash\n",
    "out = []\n",
    "for i in range(11):\n",
    "    out.append(data[data['count_nearest_ped']==i].shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,12))\n",
    "plt.bar(range(11),out)\n",
    "plt.ylabel('Counts',fontsize=20)\n",
    "plt.xlabel('Number of total crash',fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.savefig('Total crash count distribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.DataFrame(index=range(11),columns=['Total number of crash perroad segment','Percentage'])\n",
    "for i in range(11):\n",
    "    df_count.iloc[i,:]=[int(i),100*data[data['count_nearest_ped']==i].shape[0]/data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total number of crash perroad segment</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>95.7558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.97586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.627877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.120637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0780261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0476905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0338631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0244096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0191891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0119932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total number of crash perroad segment Percentage\n",
       "0                                      0    95.7558\n",
       "1                                      1    2.97586\n",
       "2                                      2   0.627877\n",
       "3                                      3    0.23817\n",
       "4                                      4   0.120637\n",
       "5                                      5  0.0780261\n",
       "6                                      6  0.0476905\n",
       "7                                      7  0.0338631\n",
       "8                                      8  0.0244096\n",
       "9                                      9  0.0191891\n",
       "10                                    10  0.0119932"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_5 = data[data['count_nearest_ped']<=5]\n",
    "# data_10 = data[data['count_nearest_ped']<=10]\n",
    "# data_20 = data[data['count_nearest_ped']<=20]\n",
    "# extract a small dataset\n",
    "mask = np.random.rand(len(data)) < 0.01\n",
    "data_small = data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['DVMT','NUM_LANES','MED_WID','shoulder_w','on_system','curve_ind','MAX_EST_CU','SPD_MAX',\\\n",
    " 'AADT2', 'TRK_AADT_P','pop_den','job_den','RU_1','RU_2','RU_3','RU_4',\\\n",
    " 'PrecipInch','school_dist','HOS_DIST', 'transit_ind','Cnt_TARGET']\n",
    "\n",
    "# shit to fatal count prediction by changing the target to 'count_nearest_pedfatal'\n",
    "target = 'count_nearest_ped'\n",
    "crashTarget = 'count_nearest_ped' if target=='count_nearest_ped' else 'count_nearest_pedfatal'\n",
    "\n",
    "# categorical variables\n",
    "cat_vars = ['on_system','curve_ind','RU_1','RU_2','RU_3','RU_4','transit_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable description\n",
    "#LEN_EC= segment length, NUM_LANES= number of lanes, MED_WID= Median width, shoulder_w = shoulder width\n",
    "#on_system= on system roads =1, curve_ind= segment contains a curve =1, SUM_length = curve length\n",
    "# MAX_EST_CU = curve angle, ADT_ADJ = AADT, TRK_AADT_P = % of truck AADT, AADT2 = historical AADT per lane\n",
    "# DVMT = VMT, SPD_MAX= speed limit, RU_1= Rural (pop <5000), RU_2= Small urban (pop:5000-49999)\n",
    "# RU_3= Urbanized (Pop:50000-199999),RU_4= Large urbanized (Pop: 200000+), \n",
    "# pop_den = population density (per sq mile),job_den = job density (per sq mile),\n",
    "# PrecipInch = avg annual precipitation in inches, HOS_DIST = distance to nearest hospital (miles)\n",
    "#transit_ind = transit stop within 100 meter buffer =1,Cnt_TARGET = Number of transit stops within 100 m buffer,\n",
    "#transit_density= transit stops per mile, school_dist = distance to nearest school (miles), \n",
    "#count_nearest_ped = number of ped crashes, count_nearest_pedfatal = number of fatal ped crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_total =\"count_nearest_ped ~ \"+'+'.join(features)\n",
    "formula_fatal = 'count_nearest_pedfatal ~ '+'+'.join(features)\n",
    "formula = formula_total if target=='count_nearest_ped' else formula_fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Binomial for Bayesian Optimization \n",
    "# add get_params() and set_params() to XBART\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "# modeify NB for parameter fine tuning\n",
    "class NegativeBinomialExtend(BaseEstimator):\n",
    "    def __init__(self,alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        #take the estimator\n",
    "        self.clfs = {}\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        df_train = pd.concat([y,X], axis=1)\n",
    "        y_dmatrix, X_dmatrix = dmatrices(formula, df_train, return_type='dataframe')\n",
    "        model = sm.GLM(y_dmatrix, X_dmatrix,family=sm.families.NegativeBinomial(alpha=self.alpha))\n",
    "        model = model.fit()\n",
    "        self.clfs['model'] = model\n",
    "        return self\n",
    "    # have trouble to implement Bayesian Optimization \n",
    "    def predict(self, X, y=y_test):\n",
    "        df_test = pd.concat([y,X], axis=1)\n",
    "        y_dmatrix, X_dmatrix = dmatrices(formula, df_test, return_type='dataframe')\n",
    "        nb2_predictions = self.clfs['model'].get_prediction(X_dmatrix)\n",
    "        predictions_summary_frame = nb2_predictions.summary_frame()\n",
    "        predictions = predictions_summary_frame['mean']\n",
    "        return predictions  \n",
    "    \n",
    "    \n",
    "def NegativeBinomialBayesianOptimization(X_dtrain, y_dtrain, X_dtest, y_dtest):\n",
    "    def function(alpha):\n",
    "        return cross_val_score(NegativeBinomialExtend(alpha=alpha),  \n",
    "               X=X_dtrain, \n",
    "               y=y_dtrain, \n",
    "               cv=4,\n",
    "               scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "    parameters = {\"alpha\": (0.1,3)}\n",
    "    #optimize with BayesianOptimization\n",
    "    bayes = BayesianOptimization(function, parameters)\n",
    "    bayes.maximize(init_points=3, n_iter=7)\n",
    "    optimal_params = bayes.max['params']\n",
    "    return optimal_params   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_small[features],data_small[crashTarget],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy,xx= dmatrices(formula, data_small, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>DVMT</th>\n",
       "      <th>NUM_LANES</th>\n",
       "      <th>MED_WID</th>\n",
       "      <th>shoulder_w</th>\n",
       "      <th>on_system</th>\n",
       "      <th>curve_ind</th>\n",
       "      <th>MAX_EST_CU</th>\n",
       "      <th>SPD_MAX</th>\n",
       "      <th>AADT2</th>\n",
       "      <th>...</th>\n",
       "      <th>job_den</th>\n",
       "      <th>RU_1</th>\n",
       "      <th>RU_2</th>\n",
       "      <th>RU_3</th>\n",
       "      <th>RU_4</th>\n",
       "      <th>PrecipInch</th>\n",
       "      <th>school_dist</th>\n",
       "      <th>HOS_DIST</th>\n",
       "      <th>transit_ind</th>\n",
       "      <th>Cnt_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.557429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2791.5</td>\n",
       "      <td>...</td>\n",
       "      <td>495.036368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.849056</td>\n",
       "      <td>4.517874e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.746663</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>...</td>\n",
       "      <td>551.955677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.390873</td>\n",
       "      <td>4.438984e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.731527</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3955.0</td>\n",
       "      <td>...</td>\n",
       "      <td>374.805021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.564377</td>\n",
       "      <td>4.318257e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.516445</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.275100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.400738</td>\n",
       "      <td>3.231204e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.264678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.058278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.746451</td>\n",
       "      <td>2.754064e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708442</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.673914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>143.631642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.921102</td>\n",
       "      <td>1.876111e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708501</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.798386</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1124.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.258110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.085522</td>\n",
       "      <td>6.697016e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708659</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.152736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.053611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.205182</td>\n",
       "      <td>5.774820e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708669</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124869</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13.963525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.326927</td>\n",
       "      <td>6.312900e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708718</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.852867</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.840407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.631814</td>\n",
       "      <td>4.218006e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7020 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Intercept      DVMT  NUM_LANES  MED_WID  shoulder_w  on_system  \\\n",
       "99            1.0  6.557429        4.0      0.0         0.0        1.0   \n",
       "147           1.0  5.746663        2.0      0.0        10.0        1.0   \n",
       "220           1.0  7.731527        4.0      0.0        10.0        1.0   \n",
       "377           1.0  1.516445        2.0      0.0         2.0        1.0   \n",
       "513           1.0  5.264678        2.0      0.0         8.0        1.0   \n",
       "...           ...       ...        ...      ...         ...        ...   \n",
       "708442        1.0  1.673914        2.0      0.0         0.0        1.0   \n",
       "708501        1.0  7.798386        2.0      0.0         0.0        0.0   \n",
       "708659        1.0  3.152736        2.0      0.0         0.0        0.0   \n",
       "708669        1.0  0.124869        2.0      0.0         0.0        0.0   \n",
       "708718        1.0  3.852867        2.0      0.0         0.0        0.0   \n",
       "\n",
       "        curve_ind  MAX_EST_CU  SPD_MAX   AADT2  ...     job_den  RU_1  RU_2  \\\n",
       "99            1.0        13.7     40.0  2791.5  ...  495.036368   0.0   1.0   \n",
       "147           0.0         0.0     70.0  2787.0  ...  551.955677   1.0   0.0   \n",
       "220           0.0         0.0     45.0  3955.0  ...  374.805021   0.0   0.0   \n",
       "377           1.0        18.3     55.0   127.0  ...   10.275100   1.0   0.0   \n",
       "513           1.0        94.7     50.0   501.0  ...   39.058278   0.0   0.0   \n",
       "...           ...         ...      ...     ...  ...         ...   ...   ...   \n",
       "708442        0.0         0.0     55.0  2166.5  ...  143.631642   1.0   0.0   \n",
       "708501        0.0         0.0      0.0  1124.5  ...    8.258110   1.0   0.0   \n",
       "708659        0.0         0.0     60.0    16.0  ...   10.053611   1.0   0.0   \n",
       "708669        0.0         0.0     60.0    66.5  ...   13.963525   1.0   0.0   \n",
       "708718        0.0         0.0     60.0    31.0  ...    5.840407   1.0   0.0   \n",
       "\n",
       "        RU_3  RU_4  PrecipInch  school_dist      HOS_DIST  transit_ind  \\\n",
       "99       0.0   0.0        11.0     0.849056  4.517874e-07          0.0   \n",
       "147      0.0   0.0        11.0     9.390873  4.438984e-06          0.0   \n",
       "220      1.0   0.0        13.0     0.564377  4.318257e-07          0.0   \n",
       "377      0.0   0.0        20.0     0.400738  3.231204e-06          0.0   \n",
       "513      1.0   0.0        25.0     3.746451  2.754064e-06          0.0   \n",
       "...      ...   ...         ...          ...           ...          ...   \n",
       "708442   0.0   0.0        24.0     0.921102  1.876111e-07          0.0   \n",
       "708501   0.0   0.0        34.0     6.085522  6.697016e-06          0.0   \n",
       "708659   0.0   0.0        37.0     4.205182  5.774820e-06          0.0   \n",
       "708669   0.0   0.0        37.0     0.326927  6.312900e-06          0.0   \n",
       "708718   0.0   0.0        30.0     1.631814  4.218006e-06          0.0   \n",
       "\n",
       "        Cnt_TARGET  \n",
       "99             0.0  \n",
       "147            0.0  \n",
       "220            0.0  \n",
       "377            0.0  \n",
       "513            0.0  \n",
       "...            ...  \n",
       "708442         0.0  \n",
       "708501         0.0  \n",
       "708659         0.0  \n",
       "708669         0.0  \n",
       "708718         0.0  \n",
       "\n",
       "[7020 rows x 22 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DVMT</th>\n",
       "      <th>NUM_LANES</th>\n",
       "      <th>MED_WID</th>\n",
       "      <th>shoulder_w</th>\n",
       "      <th>on_system</th>\n",
       "      <th>curve_ind</th>\n",
       "      <th>MAX_EST_CU</th>\n",
       "      <th>SPD_MAX</th>\n",
       "      <th>AADT2</th>\n",
       "      <th>TRK_AADT_P</th>\n",
       "      <th>...</th>\n",
       "      <th>job_den</th>\n",
       "      <th>RU_1</th>\n",
       "      <th>RU_2</th>\n",
       "      <th>RU_3</th>\n",
       "      <th>RU_4</th>\n",
       "      <th>PrecipInch</th>\n",
       "      <th>school_dist</th>\n",
       "      <th>HOS_DIST</th>\n",
       "      <th>transit_ind</th>\n",
       "      <th>Cnt_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231687</th>\n",
       "      <td>5.141196</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>35.265735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.905418</td>\n",
       "      <td>2.660955e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262889</th>\n",
       "      <td>4.157570</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>35.700751</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1.220986</td>\n",
       "      <td>3.290180e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492752</th>\n",
       "      <td>3.386422</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>139.967153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1.011785</td>\n",
       "      <td>2.435010e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255346</th>\n",
       "      <td>5.461541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.253800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.943208</td>\n",
       "      <td>2.281309e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540009</th>\n",
       "      <td>1.951608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.885498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.150960</td>\n",
       "      <td>4.796142e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125937</th>\n",
       "      <td>7.306217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>65</td>\n",
       "      <td>1573.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.269536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.035293</td>\n",
       "      <td>3.440933e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519820</th>\n",
       "      <td>4.497785</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>401.524096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1.448665</td>\n",
       "      <td>9.515822e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13645</th>\n",
       "      <td>4.402417</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.4</td>\n",
       "      <td>75</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>85.375909</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5.424857</td>\n",
       "      <td>4.173417e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660652</th>\n",
       "      <td>5.358518</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>161.865876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>3.767502e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354308</th>\n",
       "      <td>3.564449</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>488.654075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.591567</td>\n",
       "      <td>6.239103e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5616 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DVMT  NUM_LANES  MED_WID  shoulder_w  on_system  curve_ind  \\\n",
       "231687  5.141196          2        0         0.0          0          0   \n",
       "262889  4.157570          2        0         0.0          0          0   \n",
       "492752  3.386422          2        0         0.0          0          0   \n",
       "255346  5.461541          2        0         0.0          0          0   \n",
       "540009  1.951608          2        0         0.0          0          0   \n",
       "...          ...        ...      ...         ...        ...        ...   \n",
       "125937  7.306217          2        0         9.0          1          1   \n",
       "519820  4.497785          2        0         0.0          0          0   \n",
       "13645   4.402417          2        0         4.0          1          1   \n",
       "660652  5.358518          2        0         0.0          0          0   \n",
       "354308  3.564449          2        0         0.0          0          0   \n",
       "\n",
       "        MAX_EST_CU  SPD_MAX   AADT2  TRK_AADT_P  ...     job_den  RU_1  RU_2  \\\n",
       "231687         0.0       60   120.0         3.2  ...   35.265735     0     1   \n",
       "262889         0.0        0   107.0         3.2  ...   35.700751     0     0   \n",
       "492752         0.0        0   127.5         3.2  ...  139.967153     0     0   \n",
       "255346         0.0        0    95.0         3.2  ...    4.253800     1     0   \n",
       "540009         0.0        0    20.0         3.2  ...    2.885498     1     0   \n",
       "...            ...      ...     ...         ...  ...         ...   ...   ...   \n",
       "125937        31.8       65  1573.5        16.1  ...   11.269536     1     0   \n",
       "519820         0.0        0   196.5         3.2  ...  401.524096     0     1   \n",
       "13645         95.4       75    34.0        17.7  ...   85.375909     1     0   \n",
       "660652         0.0        0   202.5         3.2  ...  161.865876     0     0   \n",
       "354308         0.0        0   165.0         3.2  ...  488.654075     0     0   \n",
       "\n",
       "        RU_3  RU_4  PrecipInch  school_dist      HOS_DIST  transit_ind  \\\n",
       "231687     0     0          36     2.905418  2.660955e-06            0   \n",
       "262889     0     1          52     1.220986  3.290180e-06            0   \n",
       "492752     0     1          40     1.011785  2.435010e-07            0   \n",
       "255346     0     0          39     1.943208  2.281309e-06            0   \n",
       "540009     0     0          43     0.150960  4.796142e-06            0   \n",
       "...      ...   ...         ...          ...           ...          ...   \n",
       "125937     0     0          28     3.035293  3.440933e-06            0   \n",
       "519820     0     0          56     1.448665  9.515822e-07            0   \n",
       "13645      0     0          18     5.424857  4.173417e-06            0   \n",
       "660652     0     1          34     0.062222  3.767502e-07            0   \n",
       "354308     0     1          46     0.591567  6.239103e-07            0   \n",
       "\n",
       "        Cnt_TARGET  \n",
       "231687           0  \n",
       "262889           0  \n",
       "492752           0  \n",
       "255346           0  \n",
       "540009           0  \n",
       "...            ...  \n",
       "125937           0  \n",
       "519820           0  \n",
       "13645            0  \n",
       "660652           0  \n",
       "354308           0  \n",
       "\n",
       "[5616 rows x 21 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140235    2.364975\n",
       "342895    0.003495\n",
       "267488    0.000520\n",
       "487117    0.014682\n",
       "514042    0.086727\n",
       "            ...   \n",
       "350825    0.023657\n",
       "419378    0.030714\n",
       "635768    0.004107\n",
       "628112    0.074302\n",
       "203875    0.000298\n",
       "Name: mean, Length: 1404, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NegativeBinomialExtend().fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1404, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.7888741842171594,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-908b3a1c728c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNegativeBinomialBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-ab98bfb93ae7>\u001b[0m in \u001b[0;36mNegativeBinomialBayesianOptimization\u001b[1;34m(X_dtrain, y_dtrain, X_dtest, y_dtest)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m#optimize with BayesianOptimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mbayes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mbayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0moptimal_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimal_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-ab98bfb93ae7>\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(alpha)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mNegativeBinomialBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_dtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         return cross_val_score(NegativeBinomialExtend(alpha=alpha),  \n\u001b[0m\u001b[0;32m     32\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_dtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_dtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[0;32m    213\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \"\"\"\n\u001b[1;32m--> 255\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    256\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    257\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1404, 0]"
     ]
    }
   ],
   "source": [
    "pp = NegativeBinomialBayesianOptimization(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestBayesianOptimization(X_dtrain, y_dtrain, X_dtest, y_dtest):\n",
    "    def function(n_estimators, max_depth, min_samples_split, min_samples_leaf,max_features):\n",
    "        return cross_val_score(\n",
    "               RandomForestRegressor(\n",
    "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
    "                   max_depth=int(max(max_depth,1)),\n",
    "                   min_samples_split=int(max(min_samples_split,2)),\n",
    "                   min_samples_leaf = int(max(min_samples_leaf,1)),\n",
    "                   max_features = int(max(max_features,1)),\n",
    "                   n_jobs=-1, \n",
    "                   random_state=42),  \n",
    "               X=X_dtrain, \n",
    "               y=y_dtrain, \n",
    "               cv=4,\n",
    "               scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "    parameters = {\"n_estimators\": (10, 150),\n",
    "                  \"max_depth\": (10, 100),\n",
    "                  \"min_samples_split\": (2,10),\n",
    "                 'min_samples_leaf':(1,10),\n",
    "                 'max_features':(1,10)}\n",
    "    #optimize with BayesianOptimization\n",
    "    bayes = BayesianOptimization(function, parameters)\n",
    "    bayes.maximize(init_points=3, n_iter=7)\n",
    "    optimal_params = bayes.max['params']\n",
    "    return optimal_params   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost installed from pip\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoostBayesianOptimization(X_dtrain, y_dtrain, X_dtest, y_dtest):\n",
    "    xgb_train = \n",
    "    xgb_test = \n",
    "    \n",
    "    def function(max_depth, subsample,gamma, colsample_bytree, max_leaves,max_bin, min_child_weight,colsample_bylevel,\n",
    "                reg_alpha,reg_lambda,eta):\n",
    "        params = {'objective': 'reg:squarederror',\n",
    "                  'booster':'gbtree',\n",
    "                  'max_depth': int(round(max_depth)),\n",
    "                  'subsample': max(min(subsample, 1), 0),\n",
    "                  'eta': max(eta,0),\n",
    "                  'gamma': max(gamma, 0),\n",
    "                  'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "                  'max_leaves': int(round(max_leaves)),\n",
    "                  'max_bin':int(round(max_bin)),\n",
    "                  'min_child_weight':min_child_weight,\n",
    "                  'colsample_bylevel':colsample_bylevel,\n",
    "                  'reg_alpha':max(reg_alpha, 0),\n",
    "                  'reg_lambda':max(reg_lambda, 0),\n",
    "                   'random_state':42}\n",
    "        cv_result = xgb.cv(params, xgb_train, nfold=3,seed=6, stratified=False, \n",
    "                           metrics=['rmse'],verbose_eval=25,early_stopping_rounds=50)    \n",
    "        # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "        return -1.0 * cv_result['test-rmse-mean'].iloc[-1]\n",
    "    \n",
    "    parameters = {'max_depth': (0, 12), \n",
    "                  'gamma': (0, 1),\n",
    "                  'subsample': (0.1, 0.9),\n",
    "                  'max_leaves': (1000, 2000),\n",
    "                  'colsample_bytree': (0.1, 0.9),\n",
    "                  'reg_lambda': (0.1, 2),\n",
    "                  'reg_alpha': (0.1, 2),\n",
    "                  'max_bin':(180,500),\n",
    "                  'colsample_bylevel':(0.1,0.9),\n",
    "                  'min_child_weight': (3, 20),\n",
    "                  'eta':(0,0.5)}\n",
    "    #optimize with BayesianOptimization\n",
    "    bayes = BayesianOptimization(function, parameters)\n",
    "    bayes.maximize(init_points=3, n_iter=7)\n",
    "    optimal_params = bayes.max['params']\n",
    "    return optimal_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianOptimization to fune tune parameters\n",
    "def lightGBMBayesinaOptimization(X_dtrain, y_dtrain, X_dtest, y_dtest):\n",
    "    lgb_train = \n",
    "    lgb_test = \n",
    "    def function(num_leaves, colsample_bytree, subsample, max_depth, reg_lambda, reg_alpha, min_split_gain, min_child_weight, \n",
    "                 max_bin, subsample_freq):\n",
    "        #general parameters\n",
    "        params = {'objective':'regression','boosting_type': 'gbdt','verbose': -1, 'random_state':42, 'learning_rate':0.02}\n",
    "        #fine-tuned parameters\n",
    "        params['num_leaves'] = int(round(num_leaves))\n",
    "        params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['reg_lambda'] = max(reg_lambda, 0)\n",
    "        params['reg_alpha'] = max(reg_alpha, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['max_bin']=int(round(max_bin))\n",
    "        params['subsample_freq']=int(round(subsample_freq))\n",
    "        \n",
    "        cv_result = lgb.cv(params, lgb_train, nfold=3, seed=6, stratified=False, \n",
    "                       verbose_eval=25, metrics=['rmse'],early_stopping_rounds=50)\n",
    "        return -1.0 * np.min(cv_result['rmse-mean'])\n",
    "    \n",
    "    parameters = {'num_leaves': (1000, 3000),\n",
    "                  'colsample_bytree': (0.1, 0.9),\n",
    "                  'subsample': (0.1, 0.9),\n",
    "                  'max_depth': (-1, 12),\n",
    "                  'reg_lambda': (0.1, 3),\n",
    "                  'reg_alpha': (0.1, 3),\n",
    "                  'max_bin':(180,600),\n",
    "                  'subsample_freq':(1,20),\n",
    "                  'min_split_gain': (0.1, 0.9),\n",
    "                  'min_child_weight': (3, 30)}\n",
    "    \n",
    "    #optimize with BayesianOptimization\n",
    "    bayes = BayesianOptimization(function, parameters)\n",
    "    bayes.maximize(init_points=2, n_iter=4)\n",
    "    optimal_params = bayes.max['params']\n",
    "    return optimal_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbartExtend import xbartExtendRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XBARTBayesianOptimization(X_dtrain, y_dtrain, X_dtest, y_dtest):\n",
    "    def function(num_trees, beta, num_cutpoints, n_min,max_depth_num):\n",
    "        ## may need to rewrite cross validation\n",
    "        val = cross_val_score(xbartExtendRegressor(\n",
    "                                          num_trees=int(max(num_trees,10)),\n",
    "                                          beta=max(beta,0),\n",
    "                                          num_cutpoints=int(max(num_cutpoints,2)),\n",
    "                                          n_min=max(n_min,0),\n",
    "                                          max_depth_num=int(max(max_depth_num,5))),\n",
    "                             X=X_dtrain, \n",
    "                             y=y_dtrain,\n",
    "                             scoring='neg_mean_absolute_error',\n",
    "                             cv=4).mean()\n",
    "        return val\n",
    "    \n",
    "    parameters = {'num_trees': (10,200),\n",
    "                  'beta': (0,5),\n",
    "                  'num_cutpoints': (2,200),\n",
    "                  'n_min': (0,100),\n",
    "                  'max_depth_num':(5,200)}\n",
    "    #optimize with BayesianOptimization\n",
    "    bayes = BayesianOptimization(function, parameters)\n",
    "    bayes.maximize(init_points=2, n_iter=3)\n",
    "    optimal_params = bayes.max['params']\n",
    "    return optimal_params\n",
    "\n",
    "'''computer crashed in 9th iteration of Bayesian Optimization for total count , but obtained the best params:\n",
    "target: -0.1071, beta:2.231,max_depth_num:102, n_min:69.96,num_cutpoints:128, num_trees:21.34\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_r2=[];rfr_r2=[];xgb_r2=[];lgb_r2=[];xbart_r2=[]\n",
    "nb_rmse=[];rfr_rmse=[];xgb_rmse=[];lgb_rmse=[];xbart_rmse=[]\n",
    "nb_time=[];rfr_time=[];xgb_time=[];lgb_time=[];xbart_time=[]\n",
    "final_sens={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ddata):\n",
    "    for iteration in range(10):\n",
    "        ###############################Split data for train and test##########################################################\n",
    "        X_train, X_test, y_train, y_test = train_test_split(ddata[features],ddata[crashTarget],test_size=0.2)\n",
    "        \n",
    "        ########################################Parameters fine tuning########################################################\n",
    "        nb_params = NegativeBinomialBayesianOptimization(X_train, y_train, X_test, y_test)\n",
    "        rfr_params = RandomForestBayesianOptimization(X_train, y_train, X_test, y_test)\n",
    "        # convert integer parameter to an integer\n",
    "        for para in rfr_params.keys():\n",
    "            rfr_params[para] = int(round(rfr_params[para]))\n",
    "            \n",
    "        xgb_params = XGBoostBayesianOptimization(X_train, y_train, X_test, y_test)\n",
    "        for para in ['max_depth','max_leaves','max_bin',]:\n",
    "            xgb_params[para] = int(round(xgb_params[para]))\n",
    "        xgb_general_params = {'objective': 'reg:squarederror','booster':'gbtree','random_state':42}\n",
    "        # combine two set of parameters\n",
    "        xgb_params = {**xgb_params,**xgb_general_params}\n",
    "        \n",
    "        lgb_params = lightGBMBayesinaOptimization(X_train, y_train, X_test, y_test)\n",
    "        for para in ['num_leaves','max_depth','max_bin','subsample_freq']:\n",
    "            lgb_params[para] = int(round(lgb_params[para]))\n",
    "        lgb_general_params = {'objective':'regression','boosting_type': 'gbdt','verbose': -1,'metric':'rmse','learning_rate':0.02,'random_state':42}\n",
    "        lgb_params = {**lgb_params,**lgb_general_params}\n",
    "        \n",
    "        # parameters for total crash count\n",
    "        xbart_params_total = {'beta':2.231,'max_depth_num':102, 'n_min':69.96,'num_cutpoints':128, 'num_trees':21.34}\n",
    "        xbart_params_fatal = {'beta':2.231,'max_depth_num':102, 'n_min':69.96,'num_cutpoints':128, 'num_trees':21.34}\n",
    "        xbart_params = xbart_params_total if target==target = 'count_nearest_ped' else xbart_params_fatal\n",
    "        print('Finished parameters fine tuning!\\n')\n",
    "        \n",
    "        ############################## Model fitting######################################################################\n",
    "        # Negative binomial \n",
    "        time1 = time.process_time()\n",
    "        nb_model = NegativeBinomialExtend(**nb_params).fit(X_train, y_train)\n",
    "        nb_preds = nb_model.predict(X_test, y_test)\n",
    "        time2 = time.process_time()\n",
    "        nb_time.append(time2-time1)\n",
    "        nb_r2.append(r2_score(y_test, nb_preds))\n",
    "        nb_rmse.append(mean_squared_error(y_test,nb_preds))\n",
    "            \n",
    "        # RandomForest\n",
    "        time1 = time.process_time()\n",
    "        rfr_model = RandomForestRegressor(**rfr_params).fit(X_train, y_train)\n",
    "        rfr_preds = rfr_model.predict(X_test, y_test)\n",
    "        time2 = time.process_time()\n",
    "        rfr_time.append(time2-time1)\n",
    "        rfr_r2.append(r2_score(y_test, rfr_preds))\n",
    "        rfr_rmse.append(mean_squared_error(y_test,rfr_preds))\n",
    "        \n",
    "        # XGBoost \n",
    "        time1 = time.process_time()\n",
    "        def xgb_dmagtrix(x1,y1):\n",
    "            return xgb.DMatrix(data=x1,label=y1)\n",
    "        xgb_model = xgb.train(xgb_params,xgb_dmagtrix(X_train,y_train),num_boost_round=200,evals=[(xgb_dmagtrix(X_test,y_test),'rmse')],early_stopping_rounds=50)\n",
    "        xgb_preds = xgb_model.predict(X_test)\n",
    "        time2 = time.process_time()\n",
    "        xgb_time.append(time2-time1)\n",
    "        xgb_r2.append(r2_score(y_test, xgb_preds))\n",
    "        xgb_rmse.append(mean_squared_error(y_test,xgb_preds))\n",
    "        \n",
    "        # lightGBM \n",
    "        time1 = time.process_time()\n",
    "        def lgb_dataset(x2,y2):\n",
    "            return lgb.Dataset(data=x2, label = y2,free_raw_data = False)\n",
    "        lgb_model = lgb.train(lgb_params, lgb_dataset(X_train,y_train), num_boost_round=200, valid_sets= [lgb_dataset(X_test,y_test)], early_stopping_rounds=50)\n",
    "        lgb_preds = lgb_model.predict(X_test)\n",
    "        time2 = time.process_time()\n",
    "        lgb_time.append(time2-time1)\n",
    "        lgb_r2.append(r2_score(y_test, lgb_preds))\n",
    "        lgb_rmse.append(mean_squared_error(y_test,lgb_preds))\n",
    "        \n",
    "        # XBART\n",
    "        time1 = time.process_time()\n",
    "        xbart_model = xbartExtendRegressor(**xbart_params).fit(X_train,y_train)\n",
    "        xbart_preds = xbart_model.predict(X_test)\n",
    "        time2 = time.process_time()\n",
    "        xbart_time.append(time2-time1)\n",
    "        xbart_r2.append(r2_score(y_test, xbart_preds))\n",
    "        xbart_rmse.append(mean_squared_error(y_test,xbart_preds))\n",
    "        \n",
    "        print('Finished model fitting!')\n",
    "        \n",
    "        ##################################### Sensitivity analysis#################################################################\n",
    "        def get_sensitivity(model_list):\n",
    "            columns = X_test.columns\n",
    "            regressors = ['Negative Binomial','RandomForeset','XGBoost','ligthGBM','XBART']\n",
    "            df_sensitivity = pd.DataFrame(index=regressors,columns=columns)\n",
    "\n",
    "            for i in range(len(regressors)):\n",
    "                for k,col in enumerate(columns):\n",
    "                    copy_X = copy.copy(X_test)\n",
    "                    if col in cat_vars:\n",
    "                        copy_X[col] = copy_X[col].map({0:1,1:0})\n",
    "                        df_sensitivity.iloc[i,k] = (model_list[i].predict(copy_X).mean()-y_test.mean())/y_test.mean()\n",
    "                    \n",
    "                    # need to disscuss how to deal with DVMT\n",
    "                    else: \n",
    "                        std = copy_X[col].std()\n",
    "                        copy_X[col] = copy_X[col]+std\n",
    "                        df_sensitivity.iloc[i,k] = (model_list[i].predict(copy_X).mean()-y_test.mean())/y_test.mean()\n",
    "            return df_sensitivity\n",
    "        models = [nb_model,rfr_model,xgb_model,lgb_model,xbart_model]\n",
    "        final_sens[iteration] = get_sensitivity(models)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    # use all data\n",
    "    main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallel coordinates plot\n",
    "from pandas.plotting import parallel_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar graph\n",
    "final_sens\n",
    "sens_figure = df_sensivity.T.plot.barh(figsize=(12,8),width=0.8).get_figure()\n",
    "sens_figure.savefig(title+'_sensitivity.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
